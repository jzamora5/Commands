scrapy startproject [project_name] = Create new scrapy project

scrapy startproject tutorial

In project folder

scrapy crawl [spider_name] = Run scrapy

scrapy crawl quotes

ðŸ›‘ SCRAPY SHELL =============================================================================

scrapy shell 'url'

scrapy shell 'https://quotes.toscrape.com/page/1/'

response.xpath('//h1/a/text()').get() = Trae el nodo de XPath correspondiente

response.xpath('//span[@class="text" and @itemprop="text"]/text()').getall() = Traer varios nodos


Request/Response Methods

request.encoding

request.method

response.status

response.headers

response.body


INSIDE PROJECT FOLDER

scrapy crawl [name_of_spider] = Run spider

scrapy crawl quotes


ðŸ›‘ XPATH =============================================================================

scrapy shell "https://quotes.toscrape.com/"

Top Ten Tags

response.xpath('//div[contains(@class, "tags-box")]//span[@class="tag-item"]/a/text()').getall()


ðŸ›‘ OUTPUT TO FILE ========================================================================

In Folder having the spider method as a generator function

Each time the command is run, information is APPENDED

Solution is to erase file before if needed


scrapy [spider] crawl -o archivo.json = En JSON

scrapy crawl quotes -o quotes.json

scrapy [spider] crawl -o archivo.csv = En CSV

scrapy crawl quotes -o quotes.csv


SI SE CONFIGURA custom_settings en el Spider no es necesario el -o

scrapy crawl quotes

ðŸ›‘ Pass arguments to Spider ========================================================================

With flag -a 

crapy crawl spider -a argument=value

In spider you get it with getattr(self, 'variable', None)

Example:

scrapy crawl quotes -a top=3

top = getattr(self, 'top', None)

ðŸŽˆ MULTIPLE ARGUMENTS

crapy crawl spider -a argument1=value -a argument2=value2

ðŸ›‘ In SHELL ========================================================================

GO TO ANOTHER URL

fetch(url)




